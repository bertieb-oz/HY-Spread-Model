"""
US High Yield Spread Rich/Cheap Model
======================================
A Streamlit web application that uses rolling multiple linear regression
to determine if US High Yield credit spreads are rich, cheap, or neutral
relative to fundamental market drivers.

Supports dynamic variable intake â€” any number of independent variables
with feature flags controlling how each is transformed.

Author: Generated by Claude
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import io
from datetime import datetime

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Page config
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="HY Spread Rich/Cheap Model",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Custom CSS
st.markdown("""
<style>
    .signal-box {
        padding: 24px; border-radius: 12px; text-align: center;
        margin-bottom: 16px; color: white; font-weight: bold;
    }
    .signal-cheap { background: linear-gradient(135deg, #1b8a3d, #27ae60); }
    .signal-rich  { background: linear-gradient(135deg, #c0392b, #e74c3c); }
    .signal-neutral { background: linear-gradient(135deg, #636e72, #95a5a6); }
    .metric-card {
        background: #f8f9fa; border-radius: 8px; padding: 16px;
        border-left: 4px solid #3498db; margin-bottom: 8px;
    }
    div[data-testid="stSidebar"] { background-color: #f0f2f6; }
</style>
""", unsafe_allow_html=True)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Constants for auto-detection
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATE_ALIASES = ["date"]
HY_SPREAD_ALIASES = [
    "us high yield spread", "hy spread", "hy_spread", "high yield spread",
    "us hy spread", "hy oas", "us high yield oas",
]

VALID_FLAGS = {"L", "LM", "LMP", "MP", "P", "N"}
DEFAULT_FLAG = "LM"

FLAG_DESCRIPTIONS = {
    "L": "Level",
    "LM": "Level + MoM Change",
    "LMP": "Level + MoM Change + % Change",
    "MP": "MoM Change + % Change",
    "P": "% Change",
    "N": "Excluded",
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Data loading & feature engineering
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _match_column(df_columns, aliases):
    """Fuzzy-match a DataFrame column against a list of aliases (case-insensitive)."""
    lower_cols = {}
    for c in df_columns:
        try:
            lower_cols[str(c).strip().lower()] = c
        except Exception:
            continue
    for alias in aliases:
        if alias in lower_cols:
            return lower_cols[alias]
    return None


def load_data(uploaded_file):
    """
    Load and validate the uploaded Excel file.

    Expected format:
        Row 1: Column headers
        Row 2: Feature flags (L / LM / LMP / MP / P / N) â€” blank for Date and HY Spread
        Row 3+: Data

    Returns:
        df: cleaned DataFrame with standardised column names
        dep_var_col: original name of the dependent variable column
        variable_flags: dict mapping {internal_col_name: flag} for independent variables
        original_names: dict mapping {internal_col_name: original_col_name} for display
    """
    # Read the raw file â€” row 0 = headers, row 1 = flags, rows 2+ = data
    try:
        raw = pd.read_excel(uploaded_file, header=None)
    except Exception as e:
        st.error(f"âŒ Could not read Excel file: {e}")
        return None, None, None, None

    if len(raw) < 3:
        st.error("âŒ File must have at least 3 rows: headers (row 1), flags (row 2), and data (row 3+).")
        return None, None, None, None

    # Extract headers and flag row
    headers = [str(h).strip() for h in raw.iloc[0]]
    flag_row = [str(f).strip().upper() for f in raw.iloc[1]]

    # Build DataFrame from data rows (row index 2 onward)
    df = raw.iloc[2:].reset_index(drop=True)
    df.columns = headers

    # --- Auto-detect Date column ---
    date_col = _match_column(headers, DATE_ALIASES)
    if date_col is None:
        # Try to find a column that parses as dates
        for h in headers:
            try:
                test = pd.to_datetime(df[h], errors="coerce")
                if test.notna().sum() > len(df) * 0.5:
                    date_col = h
                    break
            except Exception:
                continue
    if date_col is None:
        st.error("âŒ Could not find a Date column. Please ensure your first column is named 'Date'.")
        return None, None, None, None

    # --- Auto-detect HY Spread (dependent variable) ---
    dep_var_col = _match_column(headers, HY_SPREAD_ALIASES)
    if dep_var_col is None:
        st.error("âŒ Could not find the HY Spread column. Expected one of: " +
                 ", ".join(f"'{a}'" for a in HY_SPREAD_ALIASES))
        return None, None, None, None

    # --- Parse flags for all other columns ---
    header_to_idx = {h: i for i, h in enumerate(headers)}
    variable_flags = {}  # internal_name -> flag
    original_names = {}  # internal_name -> original header

    skip_cols = {date_col, dep_var_col}
    unrecognised_flags = []

    for col_name in headers:
        if col_name in skip_cols:
            continue
        idx = header_to_idx[col_name]
        raw_flag = flag_row[idx] if idx < len(flag_row) else ""

        # Skip columns with no header or nonsense headers
        if col_name.lower() in ("", "nan", "none"):
            continue

        # Parse flag
        if raw_flag in VALID_FLAGS:
            flag = raw_flag
        elif raw_flag in ("", "NAN", "NONE", "NAT"):
            flag = DEFAULT_FLAG  # default if blank
        else:
            unrecognised_flags.append((col_name, raw_flag))
            flag = DEFAULT_FLAG

        # Create a safe internal name (lowercase, underscores)
        internal = col_name.strip().lower().replace(" ", "_").replace("&", "and")
        internal = "".join(c if c.isalnum() or c == "_" else "_" for c in internal)

        variable_flags[internal] = flag
        original_names[internal] = col_name

    if unrecognised_flags:
        flag_list = ", ".join(f"'{col}' â†’ '{f}'" for col, f in unrecognised_flags)
        st.warning(f"âš ï¸ Unrecognised flags (defaulting to {DEFAULT_FLAG}): {flag_list}. "
                   f"Valid flags: {', '.join(sorted(VALID_FLAGS))}")

    # Filter out all N-flagged columns
    active_vars = {k: v for k, v in variable_flags.items() if v != "N"}
    if not active_vars:
        st.error("âŒ All independent variables are flagged 'N' (excluded). At least one variable must be included.")
        return None, None, None, None

    # --- Build clean DataFrame ---
    # Rename to internal names
    rename_map = {date_col: "date", dep_var_col: "hy_spread"}
    for internal, orig in original_names.items():
        rename_map[orig] = internal

    df = df.rename(columns=rename_map)

    # Keep only columns we need
    keep_cols = ["date", "hy_spread"] + list(original_names.keys())
    keep_cols = [c for c in keep_cols if c in df.columns]
    df = df[keep_cols].copy()

    # Convert types
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    for c in df.columns:
        if c != "date":
            df[c] = pd.to_numeric(df[c], errors="coerce")

    df = df.dropna(subset=["date"]).sort_values("date").reset_index(drop=True)
    df = df.ffill()  # forward-fill minor gaps

    return df, dep_var_col, variable_flags, original_names


def engineer_features(df, variable_flags, original_names):
    """
    Create derived features based on each variable's flag.

    Flags:
        L   â†’ level only
        LM  â†’ level + monthly change
        LMP â†’ level + monthly change + % change
        MP  â†’ monthly change + % change
        P   â†’ % change only
        N   â†’ excluded (already filtered out before this call)

    For flags that generate both MoM change and % change (LMP, MP), both are
    generated here but tracked as competing pairs. The selection of which to
    use happens inside run_regression() on a per-window basis.

    Returns:
        feat_df: DataFrame with date, hy_spread, and all derived feature columns
        feature_cols: list of ALL derived feature column names (including both candidates)
        feature_labels: dict mapping feature_col â†’ display label
        competing_pairs: list of tuples (mom_col, pct_col, var_internal_name) for per-window selection
    """
    feat = df[["date", "hy_spread"]].copy()
    feature_cols = []
    feature_labels = {}
    competing_pairs = []  # (mom_col, pct_col, var_internal_name)

    for var, flag in variable_flags.items():
        if flag == "N":
            continue
        if var not in df.columns:
            continue

        display_name = original_names.get(var, var)

        # Level
        if "L" in flag:
            col_name = f"{var}_level"
            feat[col_name] = df[var]
            feature_cols.append(col_name)
            feature_labels[col_name] = f"{display_name} Level"

        # Monthly change â€” flag contains "M"
        has_mom = "M" in flag
        has_pct = "P" in flag

        if has_mom:
            col_name = f"{var}_change"
            feat[col_name] = df[var].diff()
            feature_cols.append(col_name)
            feature_labels[col_name] = f"{display_name} MoM Change"

        # Percentage change â€” flag contains "P"
        if has_pct:
            col_name = f"{var}_pct_change"
            feat[col_name] = df[var].pct_change() * 100
            feature_cols.append(col_name)
            feature_labels[col_name] = f"{display_name} % Change"

        # Track competing pairs (both MoM and Pct generated)
        if has_mom and has_pct:
            competing_pairs.append((f"{var}_change", f"{var}_pct_change", var))

    feat = feat.dropna().reset_index(drop=True)

    # Replace any remaining inf values from pct_change (e.g., division by zero)
    feat = feat.replace([np.inf, -np.inf], np.nan).dropna().reset_index(drop=True)

    return feat, feature_cols, feature_labels, competing_pairs


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Regression engine
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_regression(feat_df, feature_cols, lookback, competing_pairs=None):
    """
    Run rolling-window OLS regression with per-window feature selection.

    For variables with both MoM change and % change features (competing_pairs),
    at each rolling window the function selects the transformation with higher
    absolute Pearson correlation to HY Spread. Only the winner enters the regression.

    Returns:
        results: DataFrame with predictions, residuals
        model_stats: dict with final-window statistics
        coef_df: DataFrame of coefficient history
        latest_selections: dict mapping var_internal_name â†’ 'mom' or 'pct' (latest window)
        active_feature_cols: list of feature columns actually used in the final window
    """
    if competing_pairs is None:
        competing_pairs = []

    n = len(feat_df)
    if n < lookback + 1:
        st.error(f"Not enough data ({n} rows) for a {lookback}-month lookback window.")
        return None

    X_all = feat_df[feature_cols].values
    y_all = feat_df["hy_spread"].values
    col_index = {c: i for i, c in enumerate(feature_cols)}

    # Identify which feature_cols are always included (not part of a competing pair)
    competing_mom_cols = {mom for mom, pct, var in competing_pairs}
    competing_pct_cols = {pct for mom, pct, var in competing_pairs}
    base_col_indices = [col_index[c] for c in feature_cols
                        if c not in competing_mom_cols and c not in competing_pct_cols]

    predictions = np.full(n, np.nan)
    residuals = np.full(n, np.nan)
    coef_history = []
    latest_selections = {}
    active_feature_cols = None

    for i in range(lookback, n):
        y_train = y_all[i - lookback:i]

        # Per-window feature selection for competing pairs
        window_col_indices = list(base_col_indices)
        window_selections = {}
        window_feature_names = [feature_cols[idx] for idx in base_col_indices]

        for mom_col, pct_col, var in competing_pairs:
            mom_idx = col_index[mom_col]
            pct_idx = col_index[pct_col]
            mom_vals = X_all[i - lookback:i, mom_idx]
            pct_vals = X_all[i - lookback:i, pct_idx]

            # Compute absolute Pearson correlation with HY spread over training window
            # Handle NaN by using only valid observations
            valid = ~(np.isnan(mom_vals) | np.isnan(pct_vals) | np.isnan(y_train))
            if valid.sum() < 10:
                # Fallback: include MoM if not enough data
                window_col_indices.append(mom_idx)
                window_feature_names.append(mom_col)
                window_selections[var] = "mom"
                continue

            mom_corr = abs(np.corrcoef(mom_vals[valid], y_train[valid])[0, 1])
            pct_corr = abs(np.corrcoef(pct_vals[valid], y_train[valid])[0, 1])

            if np.isnan(mom_corr):
                mom_corr = 0.0
            if np.isnan(pct_corr):
                pct_corr = 0.0

            if pct_corr > mom_corr:
                window_col_indices.append(pct_idx)
                window_feature_names.append(pct_col)
                window_selections[var] = "pct"
            else:
                window_col_indices.append(mom_idx)
                window_feature_names.append(mom_col)
                window_selections[var] = "mom"

        # Build training matrix with selected features only
        X_train = X_all[i - lookback:i][:, window_col_indices]

        # Check for NaN in training window
        mask = ~(np.isnan(X_train).any(axis=1) | np.isnan(y_train))
        if mask.sum() < 20:
            continue

        model = LinearRegression()
        model.fit(X_train[mask], y_train[mask])

        X_pred = X_all[i:i+1][:, window_col_indices]
        pred = model.predict(X_pred)[0]
        predictions[i] = pred
        residuals[i] = y_all[i] - pred
        coef_history.append({
            "idx": i,
            "date": feat_df["date"].iloc[i],
            "intercept": model.intercept_,
            **{f"coef_{c}": v for c, v in zip(window_feature_names, model.coef_)},
        })

        # Track latest window selections
        latest_selections = window_selections
        active_feature_cols = window_feature_names

    results = feat_df.copy()
    results["predicted"] = predictions
    results["residual"] = residuals

    # If no windows ran successfully, bail out
    if active_feature_cols is None:
        st.error("Regression could not produce results for any window.")
        return None

    # Full-window final model statistics (last window) â€” using selected features
    last_start = n - lookback
    y_last = y_all[last_start:n]

    # Rebuild the final window's feature selection
    final_col_indices = list(base_col_indices)
    final_feature_names = [feature_cols[idx] for idx in base_col_indices]
    for mom_col, pct_col, var in competing_pairs:
        mom_idx = col_index[mom_col]
        pct_idx = col_index[pct_col]
        if latest_selections.get(var) == "pct":
            final_col_indices.append(pct_idx)
            final_feature_names.append(pct_col)
        else:
            final_col_indices.append(mom_idx)
            final_feature_names.append(mom_col)

    X_last = X_all[last_start:n][:, final_col_indices]
    mask = ~(np.isnan(X_last).any(axis=1) | np.isnan(y_last))
    final_model = LinearRegression()
    final_model.fit(X_last[mask], y_last[mask])

    y_pred_last = final_model.predict(X_last[mask])
    ss_res = np.sum((y_last[mask] - y_pred_last) ** 2)
    ss_tot = np.sum((y_last[mask] - y_last[mask].mean()) ** 2)
    r2 = 1 - ss_res / ss_tot
    n_obs = mask.sum()
    k = len(final_feature_names)
    adj_r2 = 1 - (1 - r2) * (n_obs - 1) / (n_obs - k - 1)
    residual_std = np.sqrt(ss_res / (n_obs - k - 1))

    # Coefficient statistics
    # Add intercept column to design matrix for proper (X'X)^-1 calculation
    X_m = X_last[mask]
    X_m_with_intercept = np.column_stack([np.ones(X_m.shape[0]), X_m])
    XtX_inv = np.linalg.pinv(X_m_with_intercept.T @ X_m_with_intercept)
    # Standard errors: skip index 0 (intercept) to get SEs for coefficients only
    se = np.sqrt(np.diag(XtX_inv)[1:] * (residual_std ** 2))
    t_stats = final_model.coef_ / se
    from scipy import stats as sp_stats
    p_values = 2 * (1 - sp_stats.t.cdf(np.abs(t_stats), df=n_obs - k - 1))

    model_stats = {
        "r2": r2,
        "adj_r2": adj_r2,
        "n_obs": n_obs,
        "residual_std": residual_std,
        "coefficients": final_model.coef_,
        "intercept": final_model.intercept_,
        "std_errors": se,
        "t_stats": t_stats,
        "p_values": p_values,
    }

    coef_df = pd.DataFrame(coef_history)
    return results, model_stats, coef_df, latest_selections, final_feature_names


def calculate_signals(results, cheap_thresh, rich_thresh):
    """Calculate z-scores and trading signals."""
    valid = results["residual"].dropna()
    mean_r = valid.mean()
    std_r = valid.std()

    results["z_score"] = (results["residual"] - mean_r) / std_r

    def _signal(z):
        if pd.isna(z):
            return "N/A"
        if z > cheap_thresh:
            return "CHEAP"
        if z < -rich_thresh:
            return "RICH"
        return "NEUTRAL"

    results["signal"] = results["z_score"].apply(_signal)
    return results


def monthly_attribution(results, coef_df, feature_cols, feature_labels):
    """Calculate factor-level contribution to predicted spread changes."""
    if coef_df is None or coef_df.empty or len(coef_df) < 2:
        return None
    last = coef_df.iloc[-1]
    prev = coef_df.iloc[-2]
    idx_last = int(last["idx"])
    idx_prev = int(prev["idx"])

    attrib_rows = []
    for col in feature_cols:
        coef_key = f"coef_{col}"
        if coef_key not in last:
            continue
        coef_val = last[coef_key]
        feat_change = results[col].iloc[idx_last] - results[col].iloc[idx_prev]
        contribution = coef_val * feat_change
        attrib_rows.append({
            "Factor": feature_labels.get(col, col),
            "Coefficient": coef_val,
            "Feature Change": feat_change,
            "Contribution (spread, %)": contribution,
        })

    attrib = pd.DataFrame(attrib_rows)
    total = attrib["Contribution (spread, %)"].sum()
    attrib["% of Total"] = np.where(total != 0, attrib["Contribution (spread, %)"] / abs(total) * 100, 0)
    return attrib


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Charts
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def chart_actual_vs_predicted(results):
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=results["date"], y=results["hy_spread"],
                             name="Actual HY Spread", line=dict(color="#2980b9", width=2)))
    fig.add_trace(go.Scatter(x=results["date"], y=results["predicted"],
                             name="Predicted HY Spread", line=dict(color="#e67e22", width=2, dash="dash")))
    fig.update_layout(title="Actual vs Predicted HY Spreads",
                      xaxis_title="Date", yaxis_title="Spread (%)",
                      template="plotly_white", height=450, legend=dict(orientation="h", y=1.12))
    return fig


def chart_residuals(results, cheap_thresh, rich_thresh):
    valid = results.dropna(subset=["residual"])
    mean_r = valid["residual"].mean()
    std_r = valid["residual"].std()

    fig = go.Figure()
    colors = valid["signal"].map({"CHEAP": "#27ae60", "RICH": "#e74c3c", "NEUTRAL": "#95a5a6", "N/A": "#bdc3c7"})
    fig.add_trace(go.Scatter(x=valid["date"], y=valid["residual"], mode="lines+markers",
                             marker=dict(color=colors, size=5), line=dict(color="#7f8c8d", width=1),
                             name="Residual"))
    fig.add_hline(y=mean_r + cheap_thresh * std_r, line_dash="dash", line_color="#27ae60",
                  annotation_text=f"Cheap ({cheap_thresh}Ïƒ)")
    fig.add_hline(y=mean_r - rich_thresh * std_r, line_dash="dash", line_color="#e74c3c",
                  annotation_text=f"Rich (-{rich_thresh}Ïƒ)")
    fig.add_hline(y=mean_r, line_dash="dot", line_color="gray")
    fig.update_layout(title="Residuals Over Time", xaxis_title="Date", yaxis_title="Residual (%)",
                      template="plotly_white", height=400)
    return fig


def chart_zscore(results, cheap_thresh, rich_thresh):
    valid = results.dropna(subset=["z_score"])
    fig = go.Figure()
    colors = valid["signal"].map({"CHEAP": "#27ae60", "RICH": "#e74c3c", "NEUTRAL": "#95a5a6", "N/A": "#bdc3c7"})
    fig.add_trace(go.Bar(x=valid["date"], y=valid["z_score"],
                         marker_color=colors, name="Z-Score"))
    fig.add_hline(y=cheap_thresh, line_dash="dash", line_color="#27ae60",
                  annotation_text=f"Cheap ({cheap_thresh}Ïƒ)")
    fig.add_hline(y=-rich_thresh, line_dash="dash", line_color="#e74c3c",
                  annotation_text=f"Rich (-{rich_thresh}Ïƒ)")
    fig.add_hline(y=0, line_color="gray", line_width=0.5)
    fig.update_layout(title="Z-Score History", xaxis_title="Date", yaxis_title="Z-Score",
                      template="plotly_white", height=400)
    return fig


def chart_coefficients(model_stats, feature_cols, feature_labels):
    labels = [feature_labels.get(c, c) for c in feature_cols]
    coefs = model_stats["coefficients"]
    colors = ["#27ae60" if c > 0 else "#e74c3c" for c in coefs]
    fig = go.Figure(go.Bar(y=labels, x=coefs, orientation="h",
                           marker_color=colors, text=[f"{c:.4f}" for c in coefs],
                           textposition="outside"))
    # Dynamic height based on number of features
    bar_height = max(420, len(feature_cols) * 35 + 80)
    fig.update_layout(title="Current Regression Coefficients",
                      xaxis_title="Coefficient Value", template="plotly_white",
                      height=bar_height, margin=dict(l=200))
    return fig


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Excel export
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_excel_report(results, model_stats, raw_df, feat_df, attrib_df,
                          feature_cols, feature_labels, variable_flags, original_names):
    """Generate a multi-sheet Excel workbook."""
    try:
        from openpyxl import Workbook
        from openpyxl.styles import Font, PatternFill, Alignment, numbers, Border, Side
        from openpyxl.utils.dataframe import dataframe_to_rows
    except ImportError:
        st.error("openpyxl not installed.")
        return None

    wb = Workbook()

    header_font = Font(bold=True, color="FFFFFF", size=11)
    header_fill = PatternFill(start_color="2C3E50", end_color="2C3E50", fill_type="solid")
    green_fill = PatternFill(start_color="27AE60", end_color="27AE60", fill_type="solid")
    red_fill = PatternFill(start_color="E74C3C", end_color="E74C3C", fill_type="solid")
    gray_fill = PatternFill(start_color="95A5A6", end_color="95A5A6", fill_type="solid")
    thin_border = Border(
        left=Side(style='thin'), right=Side(style='thin'),
        top=Side(style='thin'), bottom=Side(style='thin')
    )

    def _style_header(ws, ncols):
        for col in range(1, ncols + 1):
            cell = ws.cell(row=1, column=col)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = Alignment(horizontal="center")
            cell.border = thin_border

    def _auto_width(ws):
        from openpyxl.utils import get_column_letter
        for col_idx in range(1, ws.max_column + 1):
            max_len = 0
            for row_idx in range(1, ws.max_row + 1):
                cell = ws.cell(row=row_idx, column=col_idx)
                try:
                    max_len = max(max_len, len(str(cell.value or "")))
                except:
                    pass
            col_letter = get_column_letter(col_idx)
            ws.column_dimensions[col_letter].width = min(max_len + 3, 30)

    # --- Sheet 1: Dashboard ---
    ws = wb.active
    ws.title = "Dashboard"
    latest = results.dropna(subset=["z_score"]).iloc[-1]
    ws.append(["HY Spread Rich/Cheap Model â€” Dashboard"])
    ws.merge_cells("A1:D1")
    ws["A1"].font = Font(bold=True, size=16)
    ws.append([])
    ws.append(["Generated", datetime.now().strftime("%Y-%m-%d %H:%M")])
    ws.append(["Latest Data Date", latest["date"].strftime("%Y-%m-%d")])
    ws.append([])
    ws.append(["CURRENT SIGNAL", latest["signal"]])
    sig_cell = ws.cell(row=6, column=2)
    sig_cell.font = Font(bold=True, color="FFFFFF", size=14)
    if latest["signal"] == "CHEAP":
        sig_cell.fill = green_fill
    elif latest["signal"] == "RICH":
        sig_cell.fill = red_fill
    else:
        sig_cell.fill = gray_fill
    ws.append([])
    ws.append(["Metric", "Value"])
    metrics = [
        ("Actual HY Spread", f"{latest['hy_spread']:.2f}%"),
        ("Predicted HY Spread", f"{latest['predicted']:.2f}%"),
        ("Residual", f"{latest['residual']:.2f}%"),
        ("Z-Score", f"{latest['z_score']:.2f}"),
        ("RÂ²", f"{model_stats['r2']:.4f}"),
        ("Adj RÂ²", f"{model_stats['adj_r2']:.4f}"),
        ("Features Used", str(len(feature_cols))),
    ]
    for label, val in metrics:
        ws.append([label, val])
    _auto_width(ws)

    # --- Sheet 2: Data Input ---
    ws2 = wb.create_sheet("Data Input")
    raw_export = raw_df.copy()
    raw_export["date"] = raw_export["date"].dt.strftime("%Y-%m-%d")
    for r in dataframe_to_rows(raw_export, index=False, header=True):
        ws2.append(r)
    _style_header(ws2, len(raw_export.columns))
    _auto_width(ws2)

    # --- Sheet 3: Calculated Features ---
    ws3 = wb.create_sheet("Calculated Features")
    feat_export = feat_df.copy()
    feat_export["date"] = feat_export["date"].dt.strftime("%Y-%m-%d")
    for r in dataframe_to_rows(feat_export, index=False, header=True):
        ws3.append(r)
    _style_header(ws3, len(feat_export.columns))
    _auto_width(ws3)

    # --- Sheet 4: Model Statistics ---
    ws4 = wb.create_sheet("Model Statistics")
    ws4.append(["Feature", "Coefficient", "Std Error", "T-Statistic", "P-Value"])
    _style_header(ws4, 5)
    for i, col in enumerate(feature_cols):
        ws4.append([
            feature_labels.get(col, col),
            round(float(model_stats["coefficients"][i]), 6),
            round(float(model_stats["std_errors"][i]), 6),
            round(float(model_stats["t_stats"][i]), 4),
            round(float(model_stats["p_values"][i]), 6),
        ])
    ws4.append([])
    ws4.append(["Intercept", round(float(model_stats["intercept"]), 6)])
    ws4.append(["RÂ²", round(float(model_stats["r2"]), 6)])
    ws4.append(["Adjusted RÂ²", round(float(model_stats["adj_r2"]), 6)])
    ws4.append(["Observations", int(model_stats["n_obs"])])
    ws4.append(["Residual Std Dev", round(float(model_stats["residual_std"]), 6)])
    _auto_width(ws4)

    # --- Sheet 5: Variable Configuration ---
    ws_vars = wb.create_sheet("Variable Config")
    ws_vars.append(["Variable", "Flag", "Derived Features"])
    _style_header(ws_vars, 3)
    for var, flag in variable_flags.items():
        display = original_names.get(var, var)
        desc = FLAG_DESCRIPTIONS.get(flag, flag)
        ws_vars.append([display, flag, desc])
    _auto_width(ws_vars)

    # --- Sheet 6: Historical Signals ---
    ws5 = wb.create_sheet("Historical Signals")
    hist = results.dropna(subset=["predicted"])[["date", "hy_spread", "predicted", "residual", "z_score", "signal"]].copy()
    hist["date"] = hist["date"].dt.strftime("%Y-%m-%d")
    hist.columns = ["Date", "HY Spread", "Predicted", "Residual", "Z-Score", "Signal"]
    for r in dataframe_to_rows(hist, index=False, header=True):
        ws5.append(r)
    _style_header(ws5, 6)
    for row in range(2, ws5.max_row + 1):
        sig = ws5.cell(row=row, column=6).value
        if sig == "CHEAP":
            ws5.cell(row=row, column=6).fill = PatternFill(start_color="C8E6C9", fill_type="solid")
        elif sig == "RICH":
            ws5.cell(row=row, column=6).fill = PatternFill(start_color="FFCDD2", fill_type="solid")
    _auto_width(ws5)

    # --- Sheet 7: Instructions ---
    ws6 = wb.create_sheet("Instructions")
    instructions = [
        ["How to Interpret This Model"],
        [""],
        ["This model uses rolling multiple linear regression to predict US High Yield spreads"],
        ["based on user-configured market factors with dynamic feature engineering."],
        [""],
        ["Feature Flags (Row 2 of input file):"],
        ["L = Level only"],
        ["LM = Level + Month-over-Month Change"],
        ["LMP = Level + Month-over-Month Change + Percentage Change"],
        ["MP = Month-over-Month Change + Percentage Change"],
        ["P = Percentage Change only"],
        ["N = Exclude variable from model"],
        [""],
        ["Key Concepts:"],
        ["- Predicted Spread: the model's 'fair value' estimate for HY spreads"],
        ["- Residual: Actual minus Predicted (positive = wider than expected)"],
        ["- Z-Score: standardized residual (how many standard deviations from average)"],
        [""],
        ["Signals:"],
        ["- CHEAP: Z-Score above the cheap threshold â€” spreads are wider than expected"],
        ["  (potential buying opportunity)"],
        ["- RICH: Z-Score below the negative rich threshold â€” spreads are tighter than expected"],
        ["  (potential selling/hedging opportunity)"],
        ["- NEUTRAL: Z-Score between thresholds â€” no strong signal"],
        [""],
        ["Asymmetric Thresholds:"],
        ["The model uses different thresholds for RICH vs CHEAP because selling HY bonds"],
        ["means giving up carry income (4-6% per year). A stronger signal is required to"],
        ["justify selling (RICH) compared to buying (CHEAP)."],
    ]
    for row in instructions:
        ws6.append(row)
    ws6["A1"].font = Font(bold=True, size=14)
    _auto_width(ws6)

    buf = io.BytesIO()
    wb.save(buf)
    buf.seek(0)
    return buf


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit App
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    # â”€â”€ Sidebar â”€â”€
    st.sidebar.image("https://img.icons8.com/color/96/combo-chart.png", width=60)
    st.sidebar.title("HY Rich/Cheap Model")
    st.sidebar.markdown("---")

    uploaded_file = st.sidebar.file_uploader(
        "ğŸ“ Upload Excel Data",
        type=["xlsx"],
        help="Upload a .xlsx file with Row 1 = headers, Row 2 = feature flags (L/LM/LMP/MP/P/N), Row 3+ = data."
    )

    st.sidebar.markdown("### âš™ï¸ Model Settings")
    lookback = st.sidebar.select_slider(
        "Lookback Period (months)",
        options=[36, 48, 60],
        value=60,
        help="Number of months used in the rolling regression window."
    )
    cheap_thresh = st.sidebar.slider(
        "Cheap Threshold (Ïƒ)", 0.5, 2.0, 1.0, 0.1,
        help="Z-score above this â†’ CHEAP signal (buy). Lower = more sensitive."
    )
    rich_thresh = st.sidebar.slider(
        "Rich Threshold (Ïƒ)", 1.0, 3.0, 2.0, 0.1,
        help="Z-score below negative of this â†’ RICH signal (sell). Higher = stronger conviction required."
    )

    st.sidebar.markdown("---")

    # â”€â”€ Main Panel â”€â”€
    st.title("ğŸ“Š US High Yield Spread â€” Rich/Cheap Model")

    if uploaded_file is None:
        st.info("ğŸ‘ˆ Upload your Excel data file in the sidebar to get started.")
        with st.expander("â„¹ï¸ About This Model"):
            st.markdown("""
            This tool runs a **rolling multiple linear regression** to estimate the "fair value"
            of US High Yield credit spreads based on market factors you define.

            **Dynamic Variable Support:** The model accepts any number of independent variables.
            Use Row 2 of your Excel file to control how each variable is transformed:

            | Flag | Features Generated |
            |------|--------------------|
            | `L`  | Level only |
            | `LM` | Level + Month-over-Month Change |
            | `LMP`| Level + MoM Change + % Change |
            | `MP` | MoM Change + % Change |
            | `P`  | % Change only |
            | `N`  | Exclude from model |

            The **HY Spread** column is auto-detected as the dependent variable.
            The **Date** column is auto-detected. All other columns are treated as
            candidate independent variables.
            """)
        return

    # Load data
    result = load_data(uploaded_file)
    if result[0] is None:
        return
    raw_df, dep_var_col, variable_flags, original_names = result

    # Show detected configuration in sidebar
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“‹ Detected Variables")
    st.sidebar.markdown(f"**Dependent:** {dep_var_col}")
    active_count = sum(1 for f in variable_flags.values() if f != "N")
    excluded_count = sum(1 for f in variable_flags.values() if f == "N")
    st.sidebar.markdown(f"**Independent:** {active_count} active, {excluded_count} excluded")
    with st.sidebar.expander("Variable Details", expanded=False):
        for var, flag in variable_flags.items():
            display = original_names.get(var, var)
            icon = "ğŸŸ¢" if flag != "N" else "ğŸ”´"
            st.markdown(f"{icon} **{display}** â†’ `{flag}` ({FLAG_DESCRIPTIONS.get(flag, flag)})")

    # Feature engineering
    feat_df, feature_cols, feature_labels, competing_pairs = engineer_features(raw_df, variable_flags, original_names)

    if len(feature_cols) == 0:
        st.error("âŒ No features were generated. Check your feature flags.")
        return

    if len(feat_df) < lookback + 5:
        st.error(f"Not enough data ({len(feat_df)} rows after feature engineering) for {lookback}-month lookback.")
        return

    # Run model
    with st.spinner("Running rolling regression..."):
        reg_result = run_regression(feat_df, feature_cols, lookback, competing_pairs)

    if reg_result is None or reg_result[0] is None:
        return

    results, model_stats, coef_df, latest_selections, active_feature_cols = reg_result
    results = calculate_signals(results, cheap_thresh, rich_thresh)

    # Build active feature_labels for the selected features only
    active_feature_labels = {c: feature_labels.get(c, c) for c in active_feature_cols}

    # â”€â”€ Sidebar: Feature selection info (Change 1) â”€â”€
    if competing_pairs:
        st.sidebar.markdown("---")
        st.sidebar.markdown("### ğŸ”€ Feature Selection")
        st.sidebar.caption("Per-window auto-selection (latest window):")
        for mom_col, pct_col, var in competing_pairs:
            display_name = original_names.get(var, var)
            sel = latest_selections.get(var, "mom")
            if sel == "pct":
                st.sidebar.markdown(f"**{display_name}:** % Change selected *(MoM dropped)*")
            else:
                st.sidebar.markdown(f"**{display_name}:** MoM Change selected *(% dropped)*")

    # â”€â”€ Sidebar: Coefficient summary (Change 3) â”€â”€
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“Š Coefficients (Latest Window)")
    for i, col in enumerate(active_feature_cols):
        label = active_feature_labels.get(col, col)
        coef_val = model_stats["coefficients"][i]
        sign = "+" if coef_val >= 0 else ""
        st.sidebar.markdown(f"**{label}:** `{sign}{coef_val:.4f}`")

    # â”€â”€ Section 1: Current Signal â”€â”€
    latest = results.dropna(subset=["z_score"]).iloc[-1]
    prev_rows = results.dropna(subset=["z_score"])
    prev_signal = prev_rows.iloc[-2]["signal"] if len(prev_rows) >= 2 else "N/A"

    signal = latest["signal"]
    css_class = {"CHEAP": "signal-cheap", "RICH": "signal-rich"}.get(signal, "signal-neutral")
    st.markdown(f"""
    <div class="signal-box {css_class}">
        <div style="font-size:14px; opacity:0.85;">Current Signal as of {latest['date'].strftime('%B %d, %Y')}</div>
        <div style="font-size:42px; margin:8px 0;">{signal}</div>
        <div style="font-size:18px;">Z-Score: {latest['z_score']:.2f}</div>
    </div>
    """, unsafe_allow_html=True)

    # â”€â”€ Section 2: Key Metrics â”€â”€
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Actual HY Spread", f"{latest['hy_spread']:.2f}%")
    col2.metric("Predicted Spread", f"{latest['predicted']:.2f}%")
    col3.metric("Residual", f"{latest['residual']:+.2f}%")
    col4.metric("Model RÂ²", f"{model_stats['r2']:.3f}")

    col5, col6, col7, col8 = st.columns(4)
    col5.metric("Z-Score", f"{latest['z_score']:+.2f}")
    col6.metric("Signal", signal)
    col7.metric("Previous Signal", prev_signal)
    col8.metric("Adj. RÂ²", f"{model_stats['adj_r2']:.3f}")

    st.markdown("---")

    # â”€â”€ Section 3: Charts â”€â”€
    st.subheader("ğŸ“ˆ Interactive Charts")

    tab1, tab2, tab3, tab4 = st.tabs([
        "Actual vs Predicted", "Residuals", "Z-Score History", "Factor Coefficients"
    ])

    with tab1:
        st.plotly_chart(chart_actual_vs_predicted(results), use_container_width=True)
    with tab2:
        st.plotly_chart(chart_residuals(results, cheap_thresh, rich_thresh), use_container_width=True)
    with tab3:
        st.plotly_chart(chart_zscore(results, cheap_thresh, rich_thresh), use_container_width=True)
    with tab4:
        st.plotly_chart(chart_coefficients(model_stats, active_feature_cols, active_feature_labels), use_container_width=True)

    st.markdown("---")

    # â”€â”€ Section 4: Monthly Attribution â”€â”€
    with st.expander("ğŸ” Monthly Attribution Analysis", expanded=False):
        attrib = monthly_attribution(results, coef_df, active_feature_cols, active_feature_labels)
        if attrib is not None:
            st.dataframe(
                attrib.style.format({
                    "Coefficient": "{:.6f}",
                    "Feature Change": "{:.4f}",
                    "Contribution (spread, %)": "{:+.4f}",
                    "% of Total": "{:+.1f}%",
                }),
                use_container_width=True,
            )
        else:
            st.info("Not enough data points for attribution analysis.")

    # â”€â”€ Section 5: Regression Statistics â”€â”€
    with st.expander("ğŸ“‹ Regression Statistics", expanded=False):
        stats_df = pd.DataFrame({
            "Feature": [active_feature_labels.get(c, c) for c in active_feature_cols],
            "Coefficient": model_stats["coefficients"],
            "Std Error": model_stats["std_errors"],
            "T-Statistic": model_stats["t_stats"],
            "P-Value": model_stats["p_values"],
        })
        st.dataframe(
            stats_df.style.format({
                "Coefficient": "{:.6f}",
                "Std Error": "{:.6f}",
                "T-Statistic": "{:.3f}",
                "P-Value": "{:.4f}",
            }).apply(lambda x: ["background-color: #fff3cd" if v < 0.05 else "" for v in x], subset=["P-Value"]),
            use_container_width=True,
        )

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("Intercept", f"{model_stats['intercept']:.4f}")
        c2.metric("RÂ²", f"{model_stats['r2']:.4f}")
        c3.metric("Adj. RÂ²", f"{model_stats['adj_r2']:.4f}")
        c4.metric("Residual Std", f"{model_stats['residual_std']:.4f}")

    # â”€â”€ Section 6: Historical Signals â”€â”€
    with st.expander("ğŸ“… Historical Signals Table", expanded=False):
        hist = results.dropna(subset=["predicted"])[["date", "hy_spread", "predicted", "residual", "z_score", "signal"]].copy()
        hist.columns = ["Date", "HY Spread", "Predicted", "Residual", "Z-Score", "Signal"]

        def _color_signal(val):
            if val == "CHEAP":
                return "background-color: #c8e6c9; color: #1b5e20;"
            elif val == "RICH":
                return "background-color: #ffcdd2; color: #b71c1c;"
            return ""

        st.dataframe(
            hist.style.format({
                "Date": lambda x: x.strftime("%Y-%m-%d"),
                "HY Spread": "{:.2f}",
                "Predicted": "{:.2f}",
                "Residual": "{:+.3f}",
                "Z-Score": "{:+.2f}",
            }).map(_color_signal, subset=["Signal"]),
            use_container_width=True,
            height=400,
        )

    # â”€â”€ Excel Download â”€â”€
    st.markdown("---")
    attrib = monthly_attribution(results, coef_df, active_feature_cols, active_feature_labels)
    excel_buf = generate_excel_report(
        results, model_stats, raw_df, feat_df, attrib,
        active_feature_cols, active_feature_labels, variable_flags, original_names
    )
    if excel_buf:
        st.download_button(
            "ğŸ“¥ Download Excel Report",
            data=excel_buf,
            file_name=f"HY_RichCheap_Report_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.ml.sheet",
        )


if __name__ == "__main__":
    main()
